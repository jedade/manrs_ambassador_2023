{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1136.83s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/jedade/Desktop/New Folder/env/lib/python3.10/site-packages (2.0.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/jedade/Desktop/New Folder/env/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/jedade/Desktop/New Folder/env/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/jedade/Desktop/New Folder/env/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/jedade/Desktop/New Folder/env/lib/python3.10/site-packages (from pandas) (1.25.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/jedade/Desktop/New Folder/env/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#requirements for script python\n",
    "pip install pandas sqlite3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# Remplacer les valeurs vides dans une colonne par des listes vides\n",
    "def replace_empty_with_default(lst):\n",
    "    return lst if lst is not None else []\n",
    "################################################################################################################\n",
    "# Initialisation d'un dictionnaire pour stocker les relations par ASN\n",
    "asn_relations = {}\n",
    "\n",
    "# Ouvrir le fichier et lire les lignes\n",
    "with open('../manrs_08_2023/20230601.as-rel.txt', 'r') as file:\n",
    "    relationships = file.readlines()\n",
    "\n",
    "# Parcourir chaque ligne dans les relations\n",
    "for entry in relationships:\n",
    "    if entry.startswith(\"# step 1: set peering in clique\"):\n",
    "        continue\n",
    "    if entry.startswith(\"# step 2: initial provider assignment\"):\n",
    "        continue\n",
    "    if entry.startswith('# source:topology'):\n",
    "        continue\n",
    "    entry = entry.strip().split('|')\n",
    "    if len(entry) == 1:\n",
    "        # Traitement pour une seule colonne\n",
    "        continue\n",
    "    asn = entry[1]\n",
    "    data = entry[0]\n",
    "    \n",
    "    \n",
    "    if asn not in asn_relations:\n",
    "        # Si c'est la première fois que nous rencontrons cet ASN, initialiser ses relations\n",
    "        asn_relations[asn] = {\n",
    "            'asn': asn,\n",
    "            'providers': [],\n",
    "            'customers': []\n",
    "        }\n",
    "    \n",
    "        if entry[2] == '0':\n",
    "            # Si le data est 0, ajouter le data à la liste des customers\n",
    "            asn_relations[asn]['customers'].append(data)\n",
    "        elif entry[2] == '-1':\n",
    "            asn_relations[asn]['providers'].append(data)\n",
    "    else:\n",
    "        if entry[2] == '0':\n",
    "            # Si le data est 0, ajouter le data à la liste des customers\n",
    "            asn_relations[asn]['customers'].append(data)\n",
    "        elif entry[2] == '-1':\n",
    "            asn_relations[asn]['providers'].append(data)\n",
    "            \n",
    "# Convertir le dictionnaire en DataFrame\n",
    "df_relations = pd.DataFrame(list(asn_relations.values()))\n",
    "##########################################################################################################\n",
    "\n",
    "###########################################################################################################\n",
    "# Read nro-delegated-stats data\n",
    "with open('../manrs_08_2023/nro-delegated-stats', 'r') as file:\n",
    "    nro_data_brut = file.readlines()\n",
    "    \n",
    "# Read ii.as-org.v01.2023-01.json data\n",
    "with open('../manrs_08_2023/ii.as-org.v01.2023-01.json', 'r') as file:\n",
    "    asorg_data = json.load(file)\n",
    "    \n",
    "# Process nro-delegated-stats data\n",
    "results = []\n",
    "nro_datas = []\n",
    "org_datas = []\n",
    "id_counter = 1  # Initialize a counter for generating ids\n",
    "\n",
    "# Process lines\n",
    "for line in nro_data_brut:\n",
    "    if 'asn' in line and not '*' in  line:\n",
    "        nro_datas.append(line.strip().split('|'))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# Process nro-delegated-stats data\n",
    "for data in nro_datas:\n",
    "    if data[2] == 'asn':\n",
    "        if asorg_data.get(data[3]):\n",
    "            result = [id_counter, data[0], data[1], data[3], data[5], asorg_data[data[3]]['Sibling ASNs'], asorg_data[data[3]]['Name'], asorg_data[data[3]]['Website']]\n",
    "            results.append(result)\n",
    "            id_counter += 1  # Increment the id counter\n",
    "        else:\n",
    "            result = [id_counter, data[0], data[1], data[3], data[5], [], \"\", \"\"]\n",
    "            results.append(result)\n",
    "            id_counter += 1  # Increment the id counter\n",
    "\n",
    "# Create the first DataFrame\n",
    "header = ['id', 'registry', 'cc', 'asn', 'date', 'sibling_asns', 'name', 'website']\n",
    "asninfo_df = pd.DataFrame(results, columns=header)\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "##################################################################################################################\n",
    "category_df = pd.read_csv('../manrs_08_2023/2023-05_categorized_ases.csv', dtype=str)\n",
    "selected_columns = ['ASN', 'Category 1 - Layer 1', 'Category 1 - Layer 2']\n",
    "category_df = category_df.loc[:, selected_columns]\n",
    "\n",
    "#category_df = category_df[['ASN', 'Category 1 - Layer 1', 'Category 1 - Layer 2']]\n",
    "header_mapping = {'ASN': 'asn',\n",
    "                  'Category 1 - Layer 1': 'category_1',\n",
    "                  'Category 1 - Layer 2': 'category_2'}\n",
    "category_df = category_df.rename(columns=header_mapping)\n",
    "##########################################################################################################################\n",
    "\n",
    "###############################################################################################################################\n",
    "# Read rovista overview.json data\n",
    "with open('../manrs_08_2023/overview.json', 'r') as file:\n",
    "    overview_data = json.load(file)\n",
    "\n",
    "# Create a list to store extracted data\n",
    "rovs_data = []\n",
    "\n",
    "# Loop through the overview data\n",
    "for value in overview_data:\n",
    "    asn_parts = value['asn'].split(\">\")\n",
    "    if len(asn_parts) >= 2:\n",
    "        extracted_asn = asn_parts[1].split(\"<\")[0]\n",
    "        ratio_rov = value['ratio']\n",
    "        rovs_data.append({'asn': extracted_asn, 'ratio_rov': ratio_rov})\n",
    "\n",
    " # Create a DataFrame from the extracted data\n",
    "ratio_df = pd.DataFrame(rovs_data, columns=['asn', 'ratio_rov'])\n",
    "#########################################################################################################################################\n",
    "\n",
    "\n",
    "#Mergin Process\n",
    "category_df['asn'] = category_df['asn'].str.replace('AS', '')\n",
    "# Merge DataFrames\n",
    "merged_df = asninfo_df.merge(category_df, how='left', on='asn')\n",
    "merged_df = merged_df.merge(df_relations, how='left', on='asn')\n",
    "merged_df = merged_df.merge(ratio_df, how='left', on='asn')\n",
    "merged_df['asn'] = merged_df['asn'].str.replace('AS', '')\n",
    "merged_df['created_at'] = datetime.now().isoformat()\n",
    "merged_df = merged_df.fillna('')\n",
    "# Convert the 'sibling_asns', 'provider', and 'peering' columns to strings in the DataFrame\n",
    "merged_df['sibling_asns'] = merged_df['sibling_asns'].astype(str)\n",
    "merged_df['providers'] = merged_df['providers'].astype(str)\n",
    "merged_df['customers'] = merged_df['customers'].astype(str)\n",
    "\n",
    "# Save the merged DataFrame to a CSV file\n",
    "\n",
    "merged_df.to_csv('database.csv', index=False)\n",
    "\n",
    "# Create an SQLite database and save the merged DataFrame as a table\n",
    "conn = sqlite3.connect('database.db')\n",
    "merged_df.to_sql('manrs', conn, index=False, if_exists='replace')\n",
    "conn.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
